# GID-Project üóÇ
Este projeto √© um desafio de configura√ß√£o de um ambiente adequado para desenvolvimento com os frameworks Apache Airflow e DBT, al√©m de criar DAGs e modelos DBT para executar um pipeline de transforma√ß√£o de dados.


# Vis√£o Geral
O dbt (data build tool) √© uma ferramenta de linha de comando que permite que equipes de dados transformem dados em seu warehouse mais eficientemente. O Airflow √© uma plataforma para programar e monitorar fluxos de trabalho, permitindo que voc√™ orquestre suas tarefas de transforma√ß√£o de dados (dbt) e outras tarefas relacionadas.

# Pr√©-requisitos
- Conta na Google Cloud Platform (GCP) com acesso ao BigQuery
- Instala√ß√£o do dbt configurada para uso com o BigQuery
- Instala√ß√£o do Apache Airflow
- Configura√ß√£o Inicial
- OBS.: Antes de come√ßar, √© necess√°rio ter um projeto dbt configurado e pronto para ser executado. Al√©m disso, seu ambiente Airflow deve estar configurado e operacional.

# Integra√ß√£o do dbt com o Airflow
  `pip install dbt-bigquery¬¥
  
  # Passo 1: Configurar o Projeto dbt
    Certifique-se de que projeto dbt esteja configurado corretamente, com um arquivo profiles.yml que define como o dbt se conecta ao seu data warehouse.

  # Passo 2: Criar Modelos dbt
    Os modelos dbt definem as transforma√ß√µes SQL que voc√™ deseja aplicar aos seus dados. Crie modelos dbt no diret√≥rio models do seu projeto.

  # Passo 3: Testar Modelos dbt
    Execute o dbt run localmente para garantir que seus modelos sejam compilados e executados corretamente.

  # Passo 4: Criar um DAG do Airflow
    No Airflow, crie um novo DAG (Directed Acyclic Graph) que definir√° a sequ√™ncia e o agendamento das suas tarefas de transforma√ß√£o de dados.

  # Passo 5: Adicionar Tarefas dbt a DAG
    Adicione tarefas ao seu DAG para executar os comandos dbt, como dbt run e dbt test. Voc√™ pode usar o BashOperator do Airflow para chamar esses comandos.

  # Passo 6: Configurar Depend√™ncias
    Defina as depend√™ncias entre as tarefas do dbt e outras tarefas no Airflow para garantir que sejam executadas na ordem correta.

  # Passo 7: Executar a DAG
    Ative e execute o seu DAG no Airflow para testar a automa√ß√£o completa do seu pipeline de dados.
