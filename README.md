# GID-Project üóÇ
Este projeto √© um desafio de configura√ß√£o de um ambiente adequado para desenvolvimento com os frameworks Apache Airflow e DBT, al√©m de criar DAGs e modelos DBT para executar um pipeline de transforma√ß√£o de dados.


# Vis√£o Geral
O dbt (data build tool) √© uma ferramenta de linha de comando que permite que equipes de dados transformem dados em seu warehouse mais eficientemente. O Airflow √© uma plataforma para programar e monitorar fluxos de trabalho, permitindo que voc√™ orquestre suas tarefas de transforma√ß√£o de dados (dbt) e outras tarefas relacionadas.

# Pr√©-requisitos
- Conta na Google Cloud Platform (GCP) com acesso ao BigQuery
- Instala√ß√£o do dbt configurada para uso com o BigQuery
- Instala√ß√£o do Apache Airflow
- Configura√ß√£o Inicial
Antes de come√ßar, √© necess√°rio ter um projeto dbt configurado e pronto para ser executado. Al√©m disso, seu ambiente Airflow deve estar configurado e operacional.

# Integra√ß√£o do dbt com o Airflow
Passo 1: Configurar o Projeto dbt
Certifique-se de que o seu projeto dbt esteja configurado corretamente, com um arquivo profiles.yml que define como o dbt se conecta ao seu data warehouse.

# Passo 2: Criar Modelos dbt
Os modelos dbt definem as transforma√ß√µes SQL que voc√™ deseja aplicar aos seus dados. Crie modelos dbt no diret√≥rio models do seu projeto.

# Passo 3: Testar Modelos dbt
Execute o dbt run localmente para garantir que seus modelos sejam compilados e executados corretamente.

# Passo 4: Criar um DAG do Airflow
No Airflow, crie um novo DAG (Directed Acyclic Graph) que definir√° a sequ√™ncia e o agendamento das suas tarefas de transforma√ß√£o de dados.

# Passo 5: Adicionar Tarefas dbt a DAG
Adicione tarefas ao seu DAG para executar os comandos dbt, como dbt run e dbt test. Voc√™ pode usar o BashOperator do Airflow para chamar esses comandos.

# Passo 6: Configurar Depend√™ncias
Defina as depend√™ncias entre as tarefas do dbt e outras tarefas no Airflow para garantir que sejam executadas na ordem correta.

# Passo 7: Executar a DAG
Ative e execute o seu DAG no Airflow para testar a automa√ß√£o completa do seu pipeline de dados.
